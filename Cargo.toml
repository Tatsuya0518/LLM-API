[package]
name = "llm-api"
version = "0.1.0"
edition = "2021"

[dependencies]
# Burn ML Framework with CUDA backend for NVIDIA GPUs (T4, H100, A100)
burn = { version = "0.15", features = ["train", "dataset"] }
burn-cuda = "0.15"

# Tensor operations (for CPU fallback and testing)
burn-ndarray = "0.15"

# Tokenization
tokenizers = { version = "0.20", default-features = false, features = ["onig"] }

# Serialization
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"

# Async runtime
tokio = { version = "1", features = ["full"] }

# Logging
tracing = "0.1"
tracing-subscriber = "0.3"

# Utilities
anyhow = "1.0"
rand = "0.8"

[profile.release]
opt-level = 3
lto = true
codegen-units = 1
