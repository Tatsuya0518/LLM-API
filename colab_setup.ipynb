{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LLM Inference with Burn on Google Colab\n",
        "\n",
        "このノートブックは、Burn MLフレームワークを使用してGoogle Colab上でLLM推論を実行します。\n",
        "\n",
        "**対応GPU:**\n",
        "- Tesla T4 (無料版)\n",
        "- A100 (Colab Pro+)\n",
        "- H100 (Colab Enterprise)\n",
        "\n",
        "**必要な設定:**\n",
        "- ランタイムタイプ: GPU\n",
        "- GPU種類: T4, A100, またはH100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. GPU確認"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sun Jan 18 12:59:13 2026       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   49C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Rustのインストール"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Rustのインストール\n",
        "!curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh -s -- -y\n",
        "\n",
        "# 環境変数の設定\n",
        "import os\n",
        "os.environ['PATH'] = f\"/root/.cargo/bin:{os.environ['PATH']}\"\n",
        "\n",
        "# インストール確認\n",
        "!rustc --version\n",
        "!cargo --version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. CUDA開発環境の確認"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n",
            "\n",
            "/usr/lib64-nvidia\n"
          ]
        }
      ],
      "source": [
        "# CUDAバージョン確認\n",
        "!nvcc --version\n",
        "\n",
        "# CUDA環境変数の設定\n",
        "!echo $CUDA_HOME\n",
        "!echo $LD_LIBRARY_PATH"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. プロジェクトのクローン/アップロード"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'LLM-API'...\n",
            "remote: Enumerating objects: 26, done.\u001b[K\n",
            "remote: Counting objects: 100% (26/26), done.\u001b[K\n",
            "remote: Compressing objects: 100% (18/18), done.\u001b[K\n",
            "remote: Total 26 (delta 2), reused 26 (delta 2), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (26/26), 18.83 KiB | 18.83 MiB/s, done.\n",
            "Resolving deltas: 100% (2/2), done.\n",
            "/content/LLM-API\n"
          ]
        }
      ],
      "source": [
        "# 方法1: GitHubからクローン (リポジトリがある場合)\n",
        "!git clone https://github.com/Tatsuya0518/LLM-API.git\n",
        "# %cd LLM-API\n",
        "\n",
        "# 方法2: ローカルファイルをアップロード\n",
        "# 1. 左サイドバーのファイルアイコンをクリック\n",
        "# 2. LLM-APIフォルダ全体をドラッグ&ドロップ\n",
        "# 3. 以下のセルを実行してディレクトリに移動\n",
        "\n",
        "%cd /content/LLM-API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. 依存関係のビルド"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[package]\n",
            "name = \"llm-api\"\n",
            "version = \"0.1.0\"\n",
            "edition = \"2021\"\n",
            "\n",
            "[dependencies]\n",
            "# Burn ML Framework with CUDA backend for NVIDIA GPUs (T4, H100, A100)\n",
            "burn = { version = \"0.15\", features = [\"train\", \"dataset\"] }\n",
            "burn-cuda = \"0.15\"\n",
            "\n",
            "# Tensor operations (for CPU fallback and testing)\n",
            "burn-ndarray = \"0.15\"\n",
            "\n",
            "# Tokenization\n",
            "tokenizers = { version = \"0.20\", default-features = false, features = [\"onig\"] }\n",
            "\n",
            "# Serialization\n",
            "serde = { version = \"1.0\", features = [\"derive\"] }\n",
            "serde_json = \"1.0\"\n",
            "\n",
            "# Async runtime\n",
            "tokio = { version = \"1\", features = [\"full\"] }\n",
            "\n",
            "# Logging\n",
            "tracing = \"0.1\"\n",
            "tracing-subscriber = \"0.3\"\n",
            "\n",
            "# Utilities\n",
            "anyhow = \"1.0\"\n",
            "rand = \"0.8\"\n",
            "\n",
            "[profile.release]\n",
            "opt-level = 3\n",
            "lto = true\n",
            "codegen-units = 1\n"
          ]
        }
      ],
      "source": [
        "# Cargo.tomlの確認\n",
        "!cat Cargo.toml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ビルド (初回は10-20分かかります)\n",
        "!cargo build --release"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. 推論の実行"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 推論実行\n",
        "!cargo run --release"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. カスタムプロンプトで推論"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# カスタムプロンプトを使用する場合は、main.rsを編集してください\n",
        "# または、CLIオプションを追加する実装が必要です"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## トラブルシューティング\n",
        "\n",
        "### CUDAが見つからない場合\n",
        "```bash\n",
        "export CUDA_HOME=/usr/local/cuda\n",
        "export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH\n",
        "export PATH=/usr/local/cuda/bin:$PATH\n",
        "```\n",
        "\n",
        "### メモリ不足の場合\n",
        "- モデルサイズを小さくする（`ModelConfig::tiny()`を使用）\n",
        "- より大きなGPU（A100やH100）を使用\n",
        "\n",
        "### ビルドエラーの場合\n",
        "```bash\n",
        "cargo clean\n",
        "cargo build --release\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
