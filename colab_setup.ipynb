{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LLM Inference with Burn on Google Colab\n",
        "\n",
        "このノートブックは、Burn MLフレームワークを使用してGoogle Colab上でLLM推論を実行します。\n",
        "\n",
        "**対応GPU:**\n",
        "- Tesla T4 (無料版)\n",
        "- A100 (Colab Pro+)\n",
        "- H100 (Colab Enterprise)\n",
        "\n",
        "**必要な設定:**\n",
        "- ランタイムタイプ: GPU\n",
        "- GPU種類: T4, A100, またはH100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. GPU確認"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Rustのインストール"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Rustのインストール\n",
        "!curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh -s -- -y\n",
        "\n",
        "# 環境変数の設定\n",
        "import os\n",
        "os.environ['PATH'] = f\"/root/.cargo/bin:{os.environ['PATH']}\"\n",
        "\n",
        "# インストール確認\n",
        "!rustc --version\n",
        "!cargo --version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. CUDA開発環境の確認"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CUDAバージョン確認\n",
        "!nvcc --version\n",
        "\n",
        "# CUDA環境変数の設定\n",
        "!echo $CUDA_HOME\n",
        "!echo $LD_LIBRARY_PATH"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. プロジェクトのクローン/アップロード"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 方法1: GitHubからクローン (リポジトリがある場合)\n",
        "# !git clone https://github.com/YOUR_USERNAME/LLM-API.git\n",
        "# %cd LLM-API\n",
        "\n",
        "# 方法2: ローカルファイルをアップロード\n",
        "# 1. 左サイドバーのファイルアイコンをクリック\n",
        "# 2. LLM-APIフォルダ全体をドラッグ&ドロップ\n",
        "# 3. 以下のセルを実行してディレクトリに移動\n",
        "\n",
        "%cd /content/LLM-API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. 依存関係のビルド"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cargo.tomlの確認\n",
        "!cat Cargo.toml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ビルド (初回は10-20分かかります)\n",
        "!cargo build --release"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. 推論の実行"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 推論実行\n",
        "!cargo run --release"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. カスタムプロンプトで推論"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# カスタムプロンプトを使用する場合は、main.rsを編集してください\n",
        "# または、CLIオプションを追加する実装が必要です"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## トラブルシューティング\n",
        "\n",
        "### CUDAが見つからない場合\n",
        "```bash\n",
        "export CUDA_HOME=/usr/local/cuda\n",
        "export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH\n",
        "export PATH=/usr/local/cuda/bin:$PATH\n",
        "```\n",
        "\n",
        "### メモリ不足の場合\n",
        "- モデルサイズを小さくする（`ModelConfig::tiny()`を使用）\n",
        "- より大きなGPU（A100やH100）を使用\n",
        "\n",
        "### ビルドエラーの場合\n",
        "```bash\n",
        "cargo clean\n",
        "cargo build --release\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
